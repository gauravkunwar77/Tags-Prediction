{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./Train/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>How to check if an uploaded file is an image w...</td>\n",
       "      <td>&lt;p&gt;I'd like to check if an uploaded file is an...</td>\n",
       "      <td>php image-processing file-upload upload mime-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>How can I prevent firefox from closing when I ...</td>\n",
       "      <td>&lt;p&gt;In my favorite editor (vim), I regularly us...</td>\n",
       "      <td>firefox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>R Error Invalid type (list) for variable</td>\n",
       "      <td>&lt;p&gt;I am import matlab file and construct a dat...</td>\n",
       "      <td>r matlab machine-learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>How do I replace special characters in a URL?</td>\n",
       "      <td>&lt;p&gt;This is probably very simple, but I simply ...</td>\n",
       "      <td>c# url encoding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>How to modify whois contact details?</td>\n",
       "      <td>&lt;pre&gt;&lt;code&gt;function modify(.......)\\n{\\n  $mco...</td>\n",
       "      <td>php api file-get-contents</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                              Title  \\\n",
       "0   1  How to check if an uploaded file is an image w...   \n",
       "1   2  How can I prevent firefox from closing when I ...   \n",
       "2   3           R Error Invalid type (list) for variable   \n",
       "3   4      How do I replace special characters in a URL?   \n",
       "4   5               How to modify whois contact details?   \n",
       "\n",
       "                                                Body  \\\n",
       "0  <p>I'd like to check if an uploaded file is an...   \n",
       "1  <p>In my favorite editor (vim), I regularly us...   \n",
       "2  <p>I am import matlab file and construct a dat...   \n",
       "3  <p>This is probably very simple, but I simply ...   \n",
       "4  <pre><code>function modify(.......)\\n{\\n  $mco...   \n",
       "\n",
       "                                                Tags  \n",
       "0  php image-processing file-upload upload mime-t...  \n",
       "1                                            firefox  \n",
       "2                          r matlab machine-learning  \n",
       "3                                    c# url encoding  \n",
       "4                          php api file-get-contents  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6034195, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6034195, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove all the data points that exactly match the field values mention below\n",
    "\n",
    "data = df.drop_duplicates(subset={'Id', 'Title', 'Body', 'Tags'}, keep='first', inplace=False)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\MSI\n",
      "[nltk_data]     Gaming\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This cell need not run every time but only once at the beginning\n",
    "\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this', 'themselves', 'those', 'down', 'she', 'after', 've', 'while', 'once', 'your', \"hasn't\", 'no', 'further', \"needn't\", 'who', 'other', 'few', 'should', 'wouldn', 'any', 'when', 'not', 'they', 'mustn', 'do', 'very', 'that', 'it', 'from', \"you're\", \"doesn't\", 'during', 'which', 'some', 'an', 'can', 'her', 's', 'about', \"couldn't\", \"it's\", 'had', 'before', 'its', 'll', 'wasn', 'my', 'same', 'me', 'between', 'are', 'where', \"haven't\", 'own', 'there', 'shan', \"that'll\", \"should've\", 'their', 'at', \"didn't\", 'as', 'itself', 'ma', 'below', 'off', 'why', 'than', 'on', 'myself', 'and', \"won't\", 'again', 't', 'has', 'if', 'd', 'the', 'such', \"mightn't\", 'until', \"shouldn't\", 'each', 'doesn', 'through', 'hers', 'for', 'am', \"hadn't\", 'shouldn', 'or', 'against', 'were', 'more', 'being', 'out', 'but', 'hadn', 'haven', 'm', 'now', 'needn', 'weren', 'herself', 'up', 'theirs', 'him', 'above', 'both', 'because', 'by', 'have', 'yourselves', 'only', 'them', \"shan't\", 'to', 'don', \"weren't\", 'mightn', 'so', 'ourselves', 'aren', 'we', 'is', 'does', 'into', 'our', 'these', 'yourself', 'be', 'how', 'nor', 'o', 'here', 'will', \"isn't\", 'just', 'too', 'ours', 'couldn', \"don't\", 'doing', 'having', 'won', 'was', 'you', 'he', \"she's\", 'did', 're', 'with', 'been', 'most', 'his', 'didn', 'in', 'all', \"you'll\", 'under', 'then', \"wasn't\", \"aren't\", 'what', 'i', 'ain', 'himself', 'hasn', 'yours', 'y', 'isn', 'of', \"wouldn't\", \"mustn't\", \"you've\", 'whom', 'over', \"you'd\", 'a'}\n"
     ]
    }
   ],
   "source": [
    "# Printing the set of stop words present in english language\n",
    "# You need to download stopword first before using it(import nltk; nltk.download(\"stopwords\");)\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing SnowBall Stemmer\n",
    "# Stemmer convert the given word to its root word form\n",
    "\n",
    "snowball = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove texts with html tags(<...>)\n",
    "\n",
    "def clean_html(sentence):\n",
    "    # Select ANY text with < > tags\n",
    "    selected_text = re.compile('<.*?>')\n",
    "    # Replace texts enclosed in < > with white space\n",
    "    cleaned_text = re.sub(selected_text, ' ', sentence)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove punctuation marks(.,?/:;)\n",
    "\n",
    "def clean_punctuation(sentence):\n",
    "    cleaned_text = re.sub(r'[?|$|.|!]',r'', sentence)\n",
    "    cleaned_text = re.sub(r'[.|,|)|(|\\|/]',r' ', cleaned_text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Pre-processing code step-by-step(removing html tags, punctuations, stopwords, etc)\n",
    "# This may take a few minutes to execute as it needs to execute all the sentences present in data\n",
    "\n",
    "def preprocess_text(column_name):\n",
    "    initial_str = ''\n",
    "    final_str = []          # Store final string of clean words\n",
    "    s = ''\n",
    "\n",
    "    for sentence in tqdm(data[column_name].values):\n",
    "        filtered_sentence = []\n",
    "        sentence = clean_html(sentence)          # Remove html tags\n",
    "        for words in sentence.split():\n",
    "            for word in clean_punctuation(words).split():\n",
    "                if ((word.isalpha()) & (len(word) > 2)):\n",
    "                    if (word.lower() not in stop_words):\n",
    "                        s = (snowball.stem(word.lower()).encode('utf-8'))\n",
    "                        filtered_sentence.append(s)\n",
    "                    else:\n",
    "                        continue\n",
    "                else:\n",
    "                    continue\n",
    "        initial_str = b\" \".join(filtered_sentence)      # Final string of clean words\n",
    "        final_str.append(initial_str)\n",
    "    return final_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▎                                                                 | 448419/6034195 [02:19<27:09, 3428.83it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-3073121a8f57>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata_title\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Title\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Adding a column in dataset and storing cleaned text in it.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cleaned_title'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_title\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cleaned_title'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cleaned_title'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-c200a486cc80>\u001b[0m in \u001b[0;36mpreprocess_text\u001b[1;34m(column_name)\u001b[0m\n\u001b[0;32m     14\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misalpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m                         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msnowball\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m                         \u001b[0mfiltered_sentence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\stem\\snowball.py\u001b[0m in \u001b[0;36mstem\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m   1769\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mr2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"l\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"l\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1770\u001b[0m             \u001b[0mword\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1771\u001b[1;33m         \u001b[1;32melif\u001b[0m \u001b[0mr2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"e\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1772\u001b[0m             \u001b[0mword\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1773\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mr1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"e\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_title = preprocess_text(\"Title\")\n",
    "\n",
    "# Adding a column in dataset and storing cleaned text in it.\n",
    "data['cleaned_title'] = data_title\n",
    "data['cleaned_title'] = data['cleaned_title'].str.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_body = preprocess_text(\"Body\")\n",
    "\n",
    "# Adding a column in dataset and storing cleaned text in it.\n",
    "data['cleaned_body'] = data_body\n",
    "data['cleaned_body'] = data['cleaned_body'].str.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"./cleaned_text.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
